{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wisnefske Titanic Machine Learning Final Project",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lwisnefske/data-science-and-analytics-portfolio/blob/main/Wisnefske_Titanic_Machine_Learning_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tyzy-R6SQ6K"
      },
      "source": [
        "# Machine Learning: Final Project\n",
        "\n",
        "### Predicting Survival on the *Titanic*\n",
        "\n",
        "The final project is intended to simulate participation in a Kaggle competition. Your challenge is to build the most accurate model for predicting which passangers would survive the sinking of the *Titanic*. The ***Titanic Machine Learning Final Project.ipynb*** Colab notebook provides some guidance for tackling the project and suggests some things to think about as you get started. However, many of the model-building decisions are left up to you. \n",
        "**Note**: Use comments in your code and text blocks to explain your decisions and results.\n",
        "\n",
        "### Build a Pipeline for a Kaggle Competition!\n",
        "\n",
        "Kaggle was started in 2010 as a platform for machine learning competitions, which aim to identify how best to optimize supervised learning problems. These initiatives offer a two-way benefit. They help companies improve their internal algorithms and they provide prospective data professionals opportunities to prove their worth.\n",
        "\n",
        "Though Kaggle usually has a singular aim of maximizing a specific metric, the idea of finding the best possible algorithm and furthermore optimizing its hyperparameters is the daily task of a data scientist. Moreover, success in Kaggle can be great for a future resume (since your information is saved on their site).\n",
        "\n",
        "Obviously, the timeframe for this lesson is not realistic in terms of a typical Kaggle workflow, as competitors spend weeks or even months optimizing every piece of an algorithm they can. However, you can get started with preliminary testing and use these principles to enter your own Kaggle competitions in the future!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb9Fw_MKSRGj"
      },
      "source": [
        "# Step 1: Importing Libraries\n",
        "\n",
        "It is best practice to import all libraries and packages early in the process.\n",
        "\n",
        "You'll probably want to import Pandas plus some packages from scikit-learn.\n",
        "\n",
        "| Type | Path | Regression | Classification |\n",
        "| --- | --- | --- | --- |\n",
        "| **Linear Models** | `sklearn.linear_model` | `LinearRegression` | `LogisticRegression` |\n",
        "|  |  |`Ridge` | `RidgeClassifier` |\n",
        "|  |  |`Lasso` |  |\n",
        "| **K Nearest Neighbors** | `sklearn.neighbors` | `KNeighborsRegressor` | `KNeighborsClassifier` |\n",
        "| **Support Vector Machines** | `sklearn.svm.` | `SVR` | `SVC` |\n",
        "| **Naive Bayes** |  `sklearn.naive_Bayes` |  |`CategoricalNB` (Categorical) |\n",
        "|  |  |  | `MultinomialNB` (Sentiment Analysis) |\n",
        "| **Decision Trees** | `sklearn.tree` | `DecisionTreeRegressor` | `DecisionTreeClassifier` |\n",
        "| **Ensemble - Random Forests** | `sklearn.ensemble` | `RandomForestRegressor` | `RandomForestClassifier`\n",
        "| **Ensemble - Boosting** | `sklearn.ensemble` | `AdaBoostRegressor` | `AdaBoostClassifier` |\n",
        "|  | `sklearn.ensemble` | `GradientBoostRegressor` | `GradientBoostClassifier` |\n",
        "\n",
        "\n",
        "\n",
        "| Type | Path | Package |\n",
        "| --- | --- | --- |\n",
        "| Preprocessing | `sklearn.preprocessing` | `StandardScaler` |\n",
        "| |`sklearn.preprocessing` | `MinMaxScaler` |\n",
        "| |`sklearn.preprocessing` | `MaxAbsScaler` |\n",
        "| Model Selection - Splitting| `sklearn.model_selection` | `train_test_split` |\n",
        "| Model Selection - Grid Search | `sklearn.model_selection` | `GridSearchCV` |\n",
        "| Model Selection - Scoring | `sklearn.model_selection` | `cross_val_score` |\n",
        "| Metrics | `sklearn.metrics` | `confusion_matrix` |\n",
        "\n",
        "\n",
        "**Note**: Use comments in your code and text blocks to explain your decisions and results.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-q3XVj2acth"
      },
      "source": [
        "#Step 1 - import libraries/packages needed for different models\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import tree \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd1PYNlBaZUP"
      },
      "source": [
        "#Step 2:  Load the `Titanic.csv` Data\n",
        "You may want to refer back to one of your previous Colab notebooks to copy the Google Import code.\n",
        "\n",
        "**Note**: Use comments in your code and text blocks to explain your decisions and results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2YgjFdUbh6d",
        "outputId": "477ee319-faf5-4e6f-9461-b67fd3eb8a26",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "#Step 2 - upload titanic.csv dataset\n",
        "from google.colab import files\n",
        "titanic = files.upload()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3e029541-d693-4cff-b7f0-7cd50687a96e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3e029541-d693-4cff-b7f0-7cd50687a96e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Titanic.csv to Titanic (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#name titanic dataframe\n",
        "df_titanic = pd.read_csv('Titanic.csv')\n",
        "df_titanic.head()"
      ],
      "metadata": {
        "id": "NnM_ZH8evZmH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b1775338-87d0-4ff4-90e0-94498d8eb2c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc88d435-8def-47f2-8be5-2c7017bbe2f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc88d435-8def-47f2-8be5-2c7017bbe2f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cc88d435-8def-47f2-8be5-2c7017bbe2f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cc88d435-8def-47f2-8be5-2c7017bbe2f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#datatypes, dataframe shape \n",
        "print(df_titanic.dtypes)\n",
        "print(df_titanic.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Vb0NBfEEvK-",
        "outputId": "fd65f762-350d-4299-e4d9-33be1c0a6937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId      int64\n",
            "Survived         int64\n",
            "Pclass           int64\n",
            "Name            object\n",
            "Sex             object\n",
            "Age            float64\n",
            "SibSp            int64\n",
            "Parch            int64\n",
            "Ticket          object\n",
            "Fare           float64\n",
            "Cabin           object\n",
            "Embarked        object\n",
            "dtype: object\n",
            "(891, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z0J_ay1SRPz"
      },
      "source": [
        "#Step 3: Split the Data\n",
        "\n",
        "The next step is to separate the target column from the feature matrix and perform a train/test split. \n",
        "\n",
        "*   What is the target and what are the features in the data?\n",
        "*   Are there any features that you want to drop?\n",
        "*   Is there any feature engineering that you need to do?\n",
        "\n",
        "**Note**: Use comments in your code and text blocks to explain your decisions and results.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The target for this model is 'Survived.' I am trying to correctly classify whether a passenger would survive or not based on the other factors provided in the dataset. I would delete 'PassengerId', 'Name', and 'Ticket' because these do not provide any useful data, but simply identify the individual passengers. I would probably omit 'Cabin' because there are only 204 cabin numbers assigned for the 891 passengers aboard the Titanic."
      ],
      "metadata": {
        "id": "_QKyJLZE5hC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#drop columns \n",
        "df_titanic=df_titanic.drop(['PassengerId', 'Name', 'Ticket'],axis=1)"
      ],
      "metadata": {
        "id": "aWd9a9U8e3bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tmaj7Zc-kBTL"
      },
      "source": [
        "#Step 3 - define X and y \n",
        "# rerun coding dropping 'SibSp' and 'Parch' columns; 'Fare'; 'Embarked'\n",
        "\n",
        "X = df_titanic[['Pclass', 'Sex', 'Age', 'Fare', 'SibSp', 'Parch', 'Embarked']]\n",
        "y = df_titanic['Survived']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imputing embark with most common depature city\n",
        "df_titanic['Embarked']=df_titanic['Embarked'].fillna(df_titanic['Embarked'].mode()[0])"
      ],
      "metadata": {
        "id": "ggLA1PlT6fN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to use the sex of the passengers as a variable in the models, that column needs to be encoded. Since it is not an ordinal variable (there is no inherent heirarchy between male and female), I chose to use one-hot encoding. I did the same type of encoding for 'Embarked', because it is also a nominal variable.\n"
      ],
      "metadata": {
        "id": "Dce4dosyAlVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot encoding for sex of passenger\n",
        "one_hot = pd.get_dummies(data=X, columns=['Sex','Embarked'])\n",
        "\n",
        "print(one_hot.head())\n",
        "\n",
        "print(one_hot.columns)\n",
        "\n",
        "X = pd.DataFrame(one_hot)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28DO48hm43Gx",
        "outputId": "90c26bfe-4cdb-4441-8f5d-ee417a361575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Pclass   Age     Fare  SibSp  Parch  Sex_female  Sex_male  Embarked_C  \\\n",
            "0       3  22.0   7.2500      1      0           0         1           0   \n",
            "1       1  38.0  71.2833      1      0           1         0           1   \n",
            "2       3  26.0   7.9250      0      0           1         0           0   \n",
            "3       1  35.0  53.1000      1      0           1         0           0   \n",
            "4       3  35.0   8.0500      0      0           0         1           0   \n",
            "\n",
            "   Embarked_Q  Embarked_S  \n",
            "0           0           1  \n",
            "1           0           0  \n",
            "2           0           1  \n",
            "3           0           1  \n",
            "4           0           1  \n",
            "Index(['Pclass', 'Age', 'Fare', 'SibSp', 'Parch', 'Sex_female', 'Sex_male',\n",
            "       'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting dataset into training, validation, and test sets\n",
        "#training/validation and test\n",
        "\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "d2PagZRb7CG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training and validation\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.3333, random_state=42) "
      ],
      "metadata": {
        "id": "fp_N9vFj7hg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0lndw6BuQUW"
      },
      "source": [
        "#Step 4: Clean and Preprocess the Data\n",
        "\n",
        "Use the code block below to clean and preprocess your data. Some considerations you may want to think about include the following:  \n",
        "*  Are there any missing values that need to be imputed?\n",
        "*  Do you need to encode any categorical features?\n",
        "*  Do you need to standardize any quantitative features?\n",
        " \n",
        "**Note**: Use comments in your code and text blocks to explain your decisions and results.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4\n",
        "#null values\n",
        "df_titanic.isna().sum()"
      ],
      "metadata": {
        "id": "GTZ4KkS9um7t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b85d9a38-dfc7-413e-c343-b7ba93aa63cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Survived      0\n",
              "Pclass        0\n",
              "Sex           0\n",
              "Age         177\n",
              "SibSp         0\n",
              "Parch         0\n",
              "Ticket        0\n",
              "Fare          0\n",
              "Cabin       687\n",
              "Embarked      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of the twelve features in this dataset, only three of them contain null values. Even though we don't know the age of 177 passengers (approximately 20% of the total), we can easily impute this data using the average age of the remaining 714 passengers, however, that will be done *after* the data is split to avoid data leakage. Unlike the passengers' ages, their cabin number cannot be easily imputed. 687 passengers in this dataset do not have a cabin number (roughly 77% of the data). Since the cabin number likely only applies to passengers in first class and represents a small portion of the full dataset, I would remove 'Cabin' from the working dataframe instead of trying to impute a value. Lastly, two entries are missing the city of embarkment. I would replace the null value with the most popular departure city from the rest of the passengers."
      ],
      "metadata": {
        "id": "Xi5a_Cz98DvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#examine relationship between Pclass and Cabin to determine if Cabin should be imputed or dropped\n",
        "\n",
        "df_class = df_titanic[['Pclass', 'Cabin']]\n",
        "display(df_class)\n",
        "\n",
        "print((df_class == 1).sum())\n",
        "print(df_class.isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "pBysC8L03W0B",
        "outputId": "0ac74e2c-9948-40e5-f55d-8754cc95082c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     Pclass Cabin\n",
              "0         3   NaN\n",
              "1         1   C85\n",
              "2         3   NaN\n",
              "3         1  C123\n",
              "4         3   NaN\n",
              "..      ...   ...\n",
              "886       2   NaN\n",
              "887       1   B42\n",
              "888       3   NaN\n",
              "889       1  C148\n",
              "890       3   NaN\n",
              "\n",
              "[891 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f7bd4b4-359b-4f42-a148-91ea88fbac4e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Cabin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>C85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>C123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>B42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>C148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f7bd4b4-359b-4f42-a148-91ea88fbac4e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f7bd4b4-359b-4f42-a148-91ea88fbac4e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f7bd4b4-359b-4f42-a148-91ea88fbac4e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pclass    216\n",
            "Cabin       0\n",
            "dtype: int64\n",
            "Pclass      0\n",
            "Cabin     687\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Count for how many passengers in 1st class also have assigned cabin numbers\n",
        "df_titanic.value_counts([(df_titanic['Pclass']== 1) & (df_titanic['Cabin'] != np.nan)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDqUOqiyEkHx",
        "outputId": "9c856869-55b0-40c9-9a5c-f8593f8cea54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    675\n",
              "True     216\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 216 1st class passengers and 204 assigned cabin numbers. The discrepency between the two totals could be attributed to multiple passengers who are family members staying in the same cabin."
      ],
      "metadata": {
        "id": "EZaXSZrfKSY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wxU80QKR9Pr",
        "outputId": "334552a0-134d-4492-c286-45ef4cff577a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pclass          0\n",
              "Age           177\n",
              "Fare            0\n",
              "SibSp           0\n",
              "Parch           0\n",
              "Sex_female      0\n",
              "Sex_male        0\n",
              "Embarked_C      0\n",
              "Embarked_Q      0\n",
              "Embarked_S      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imputing age with mean value of remaining passengers\n",
        "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "\n",
        "X_train_ = imp_mean.fit_transform(X_train)\n",
        "                                  \n",
        "X_train = pd.DataFrame(X_train_)\n"
      ],
      "metadata": {
        "id": "mnuihZQS6Py6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcqBl3tqSRXM"
      },
      "source": [
        "#Step 5: Build the Baseline Model\n",
        "\n",
        "Ideally, you will want to set a baseline algorithm to build off of. The most logical start is *linear regression* for *regression* and *logistic regression* for *classification*, as they are the basis for their respective algorithms.\n",
        "\n",
        "Once you have the baseline set, you will want to choose an algorithm that surpasses the baseline.\n",
        "\n",
        "Select a baseline model and fit it to your data.\n",
        "\n",
        "**Note**: Use comments in your code and text blocks to explain your decisions and results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the baseline model, I am using logistic regression. This is the most basic classification algorithm we discussed in class, it is simple to understand and explain, and it's generally a good starting point when developing machine learning classification models."
      ],
      "metadata": {
        "id": "kVqwJZca-yW_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-He6s8fukCDO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21aef7e8-d1ba-4816-cced-5b916dea0a02"
      },
      "source": [
        "# Step 5 - logistic regression\n",
        "log_reg = LogisticRegression(random_state=0)\n",
        "\n",
        "log_reg_model = log_reg.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rkx6qXH3vAon"
      },
      "source": [
        "#Step 6: Evaluate the Baseline Model\n",
        "\n",
        "Use cross-validation to calculate the appropriate model evaluation metric. \n",
        "\n",
        "Is your model doing a good job fitting the data?  \n",
        "\n",
        "If you have ideas for how to improve your model fit, go back and make those changes to earlier steps.\n",
        "\n",
        "**Note**: Use comments in your code and text blocks to explain your decisions and results.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 6 - logistic regression accuracy\n",
        "\n",
        "log_accuracy = log_reg_model.score(X_train, y_train)\n",
        "\n",
        "print(log_accuracy)"
      ],
      "metadata": {
        "id": "0eTjP2jeu6v7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29ab37ee-7bff-4b0a-d4b7-74502c5d740b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.797752808988764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The baseline model is doing an adequate job of fitting the data, but the accuracy score can be improved. As it stands, the logistic regression model has approximately an 79.8% accuracy of prediction a passenger's survival on the Titanic. After removing the features with family connections (Sibsp, Parch), the accuracy decreased to 78.9%. If you only remove ticket fare (as it is closely related to passenger class), there is a marginal increase in accuracy to 79.1%, but it is still lower than the initial baseline model. Removing the embarkment cities results in an accuracy percentage of 79.3%, so like removing the fare feature, it is more accurate than removing family members but less accurate than including all of the features."
      ],
      "metadata": {
        "id": "Oawj1ndM0Ogm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDkRu0kWY6q6"
      },
      "source": [
        "# Step 7: Fit the Data to at Least One Other Model\n",
        "\n",
        "Select one (or more) other appropriate model and use it to model the data. Calculate the cross-validation accuracy of each model. \n",
        "\n",
        "**Note**: Use comments in your code and text blocks to explain your decisions and results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf-2sSGRY7Qr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd39d90a-1590-484e-a3c9-0881570d610b"
      },
      "source": [
        "#Step 7 - KNN Nearest Neighbors - create pipeline\n",
        "\n",
        "knn_pipe = Pipeline([('imp_mean',SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
        "                     ('scaler', StandardScaler()), \n",
        "                     ('KNN', KNeighborsClassifier())])\n",
        "\n",
        "knn_pipe.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('imp_mean', SimpleImputer()), ('scaler', StandardScaler()),\n",
              "                ('KNN', KNeighborsClassifier())])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN - evaluate pipeline\n",
        "\n",
        "knn_scores = cross_val_score(knn_pipe, X_train, y_train, cv=10)\n",
        "\n",
        "print(knn_scores)\n",
        "\n",
        "print(knn_scores.mean())\n",
        "print(knn_scores.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMsCbNGI8BW3",
        "outputId": "ddc67899-d138-4ff6-a44b-206821737a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.77777778 0.88888889 0.8        0.8        0.71111111 0.81818182\n",
            " 0.75       0.77272727 0.81818182 0.79545455]\n",
            "0.7932323232323233\n",
            "0.04445660990526551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the initial KNN evaluation, the 10 iterations of cross validation had a mean accuracy percent of 79.3%, half a percentage point lower than the first rendition of the logistic regression model. The standard deviation of .044 indicates that all the scores within the cross validation were consistently similar to each other."
      ],
      "metadata": {
        "id": "s8O4c7LNAwFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN - plot values for ideal K\n",
        "\n",
        "k = list(range(2,11))\n",
        "mean_accuracy = []\n",
        "\n",
        "for i in k:\n",
        "  knn_pipe = Pipeline([('imp_mean',SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
        "                       ('scaler', StandardScaler()), \n",
        "                     ('KNN', KNeighborsClassifier(n_neighbors=i))])\n",
        "\n",
        "  knn_pipe.fit(X_train, y_train)\n",
        "  scores = cross_val_score(knn_pipe, X_train, y_train, cv=10)\n",
        "  mean_accuracy.append(scores.mean())\n",
        "\n",
        "\n",
        "k_knn_df = pd.DataFrame(k)\n",
        "k_knn_df.rename({0:'k'}, axis=1, inplace=True)\n",
        "\n",
        "mean_accuracy_knn = pd.DataFrame(mean_accuracy)*100\n",
        "mean_accuracy_knn.rename({0:'knn mean accuracy'}, axis=1, inplace=True)\n",
        "\n",
        "to_plot = pd.concat([k_knn_df, mean_accuracy_knn], axis=1)\n",
        "\n",
        "plt.plot(to_plot['k'], to_plot['knn mean accuracy'])\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('KNN Mean Accuracy %')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "1cf_L4DS8zfu",
        "outputId": "8a6cca61-eb0b-4945-e256-bb94331705e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two k values that have the highest mean accuracy percentage are 4 and 6. While 4 is slightly less accurate than 6, the difference is negligible. In my final pipeline, I will use 4 because it is the smallest value of k with the highest percentage. By using the smaller k value, it should take less time to run the algorithm and use less memory."
      ],
      "metadata": {
        "id": "AqeKhywLBoBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#final knn pipeline with k = 4\n",
        "\n",
        "knn_pipe_4 = Pipeline([('imp_mean',SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
        "                     ('scaler', StandardScaler()), \n",
        "                     ('KNN', KNeighborsClassifier(n_neighbors = 4))])\n",
        "\n",
        "knn_pipe_4.fit(X_train, y_train)\n",
        "\n",
        "knn_p4_scores = cross_val_score(knn_pipe_4, X_train, y_train, cv=10)\n",
        "\n",
        "print(knn_p4_scores)\n",
        "\n",
        "print(knn_p4_scores.mean())\n",
        "print(knn_p4_scores.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Yy6eEMP95hH",
        "outputId": "9c3c06e7-abbb-44d4-cbb1-62a3af060921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.82222222 0.88888889 0.82222222 0.75555556 0.75555556 0.86363636\n",
            " 0.81818182 0.75       0.81818182 0.81818182]\n",
            "0.8112626262626262\n",
            "0.04371768633353451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final KNN Nearest Neighbors pipeline has an average accuracy score of .811 and a standard deviation of .044. This model has produced the highest accuracy thus far, and can accurately predict if someone survived the sinking of the Titanic 81.1% of the time. It also has a similar standard deviation to the cross validation scores of the first KNN model, so the scores are also consistent within themselves."
      ],
      "metadata": {
        "id": "-9qwOBIC-SsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive Bayes (Gaussian) Classification Model - build pipeline\n",
        "\n",
        "nb_pipe = Pipeline([('imp_mean',SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
        "                     ('scaler', StandardScaler()), \n",
        "                     ('nb', GaussianNB())])\n",
        "\n",
        "nb_pipe.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBYtheAj00Fw",
        "outputId": "5ff8b24b-e471-4a35-cb81-7932edde0b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('imp_mean', SimpleImputer()), ('scaler', StandardScaler()),\n",
              "                ('nb', GaussianNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NB - evaluate pipeline\n",
        "\n",
        "nb_scores = cross_val_score(nb_pipe, X_train, y_train, cv=10)\n",
        "\n",
        "print(nb_scores)\n",
        "\n",
        "print(nb_scores.mean())\n",
        "print(nb_scores.std())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPzzjxTZAHHO",
        "outputId": "d608c593-b1ad-4e9d-80fb-7b291e754d9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.71111111 0.77777778 0.82222222 0.8        0.73333333 0.84090909\n",
            " 0.75       0.72727273 0.86363636 0.70454545]\n",
            "0.7730808080808081\n",
            "0.05358252638655555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of the three models so far, the Naive Bayes Classification Model has the lowest accuracy score. With the 10-fold cross validation, its mean score is .773, .016 lower than the worst performing logistic regression model. The Naive Bayes model correctly classified survivors 77.3% of the time. With a standard deviation of .053, the scores were once again very consistent."
      ],
      "metadata": {
        "id": "_DUuFJ-zE9gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree Classifier - build pipeline\n",
        "tree_pipe = Pipeline([('imp_mean',SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
        "                     ('scaler', StandardScaler()), \n",
        "                     ('tree', DecisionTreeClassifier(criterion='entropy',random_state=42))])\n",
        "\n",
        "tree_pipe.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-LNola0-1X5",
        "outputId": "0c36c562-8de5-4b0e-dc17-94a5cc504449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('imp_mean', SimpleImputer()), ('scaler', StandardScaler()),\n",
              "                ('tree',\n",
              "                 DecisionTreeClassifier(criterion='entropy', random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tree - evaluate entropy tree\n",
        "tree_scores = cross_val_score(tree_pipe, X_train, y_train, cv=10)\n",
        "\n",
        "print(tree_scores)\n",
        "\n",
        "print(tree_scores.mean())\n",
        "print(tree_scores.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXiDH6tVH0WY",
        "outputId": "1e43538d-1676-4c97-98a9-84a77b383088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8        0.86666667 0.82222222 0.68888889 0.8        0.68181818\n",
            " 0.79545455 0.54545455 0.70454545 0.70454545]\n",
            "0.7409595959595962\n",
            "0.08912372846562658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The decision tree using entropy as its classifier has the lowest accuracy mean of all the the models and their respective variations. With an accuracy of percentage 74.1%, the model would accurately predict survival 3 out of every 4 times. While the standard deviation is still relatively low (.089), it's about twice as much as the other models. This group of scores is the least consistent. "
      ],
      "metadata": {
        "id": "oBq3tFcFNb--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tree - build pipeline 2\n",
        "tree_2_pipe = Pipeline([('imp_mean',SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
        "                     ('scaler', StandardScaler()), \n",
        "                     ('tree_2', DecisionTreeClassifier(criterion='gini',random_state=42))])\n",
        "\n",
        "tree_2_pipe.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWehHasuIsGG",
        "outputId": "5dc9e716-c136-489b-8f1d-935347eed1a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('imp_mean', SimpleImputer()), ('scaler', StandardScaler()),\n",
              "                ('tree_2', DecisionTreeClassifier(random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tree - evaluate gini tree\n",
        "tree_2_scores = cross_val_score(tree_2_pipe, X_train, y_train, cv=10)\n",
        "\n",
        "print(tree_2_scores)\n",
        "\n",
        "print(tree_2_scores.mean())\n",
        "print(tree_2_scores.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGD4k8OQIiTQ",
        "outputId": "81c9e45a-66d4-4465-a42e-d181f4da37cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.77777778 0.86666667 0.84444444 0.66666667 0.8        0.75\n",
            " 0.84090909 0.65909091 0.72727273 0.75      ]\n",
            "0.7682828282828283\n",
            "0.06815405345649489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Decision Tree Classifier that uses Gini as the criterion is the second worst performing model, only performing better than the first decision tree. The mean accuracy of the 10-fold cross validation is .768, which is .027 higher than the first decision tree, and half a percentage point lower than the Naive Bayes model. The .068 standard deviation is lower than the first tree, but higher than the rest of the models. "
      ],
      "metadata": {
        "id": "yXtVXzueOng0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#AdaBoost Classifier - build pipeline\n",
        "ab_pipe = Pipeline([('imp_mean',SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
        "                     ('scaler', StandardScaler()), \n",
        "                     ('ada', AdaBoostClassifier(random_state=42))])\n",
        "\n",
        "ab_pipe.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoH5HkWIRJ6f",
        "outputId": "2c7c82f5-88c4-4f5e-efc4-c50bcd7ffdd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('imp_mean', SimpleImputer()), ('scaler', StandardScaler()),\n",
              "                ('ada', AdaBoostClassifier(random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adaboost Classifier - evaluate pipeline\n",
        "ab_scores = cross_val_score(ab_pipe, X_train, y_train, cv=10)\n",
        "\n",
        "print(ab_scores)\n",
        "\n",
        "print(ab_scores.mean())\n",
        "print(ab_scores.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSPH8rd6UJG4",
        "outputId": "8c94ea5e-4693-4f8b-d41e-0aa1cdf217d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.75555556 0.77777778 0.86666667 0.8        0.77777778 0.84090909\n",
            " 0.84090909 0.75       0.84090909 0.70454545]\n",
            "0.7955050505050505\n",
            "0.04882375764189461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The AdaBoost Classifier Model has an mean accuracy score of .796 and a standard deviation of .049. The model correctly classified a passenger's survival on average 79.6% of the time. The accuracy scores throughout the 10-fold cross validation process were fairly consistent, as indicated by the .049 standard deviation."
      ],
      "metadata": {
        "id": "WmU7D_GrVq_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gradient Boost Classifier - build pipeline\n",
        "\n",
        "gb_pipe = Pipeline([('imp_mean',SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
        "                     ('scaler', StandardScaler()), \n",
        "                     ('Gradient', GradientBoostingClassifier(random_state=42))])\n",
        "\n",
        "gb_pipe.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjTnGZRzSc3A",
        "outputId": "b38d53c5-523e-4b23-b320-c3c0f8a31a0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('imp_mean', SimpleImputer()), ('scaler', StandardScaler()),\n",
              "                ('Gradient', GradientBoostingClassifier(random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GB Boost - evaluate pipeline\n",
        "\n",
        "gb_scores = cross_val_score(gb_pipe, X_train, y_train, cv=10)\n",
        "\n",
        "print(gb_scores)\n",
        "\n",
        "print(gb_scores.mean())\n",
        "print(gb_scores.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc_RtxY6TgQr",
        "outputId": "76c09995-c4d2-4022-8b9f-21e165e85320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.84444444 0.88888889 0.88888889 0.86666667 0.8        0.81818182\n",
            " 0.84090909 0.75       0.81818182 0.75      ]\n",
            "0.8266161616161616\n",
            "0.047405413587740704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The GradientBoost Classification Model has the highest mean accuracy score and a relatively low standard deviation. Not only are the scores from the 10-fold cross validation process consistent with each other, the model correctly classified a passenger's survival 82.6% of the time, 1.5% higher than the KNN Nearest Neighbors Model (the previous best performing model)."
      ],
      "metadata": {
        "id": "mC_BqoxEVx1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_accuracy = []\n",
        "\n",
        "for i in [0.10, 0.20, 0.30, 0.40, 0.50]:\n",
        "  gb_pipe = Pipeline([('imp_mean',SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
        "                     ('scaler', StandardScaler()), \n",
        "                     ('Gradient', GradientBoostingClassifier(random_state=42, learning_rate=i))])\n",
        "\n",
        "  gb_pipe.fit(X_train, y_train)\n",
        "  gb_scores = cross_val_score(gb_pipe, X_train, y_train, cv=10)\n",
        "  mean_accuracy.append(gb_scores.mean())\n",
        "\n",
        "\n",
        "learning_rate_gb = pd.DataFrame([0.10, 0.20, 0.30, 0.40, 0.50])\n",
        "learning_rate_gb.rename({0:'gb learning rate'}, axis=1, inplace=True)\n",
        "\n",
        "mean_accuracy_gb = pd.DataFrame(mean_accuracy)*100\n",
        "mean_accuracy_gb.rename({0:'gb mean accuracy'}, axis=1, inplace=True)\n",
        "\n",
        "to_plot = pd.concat([learning_rate_gb, mean_accuracy_gb], axis=1)\n",
        "\n",
        "print(to_plot)\n",
        "\n",
        "plt.plot(to_plot['gb learning rate'], to_plot['gb mean accuracy'])\n",
        "plt.xlabel('GB Learning Rate')\n",
        "plt.ylabel('GB Mean accuracy %')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "qDa0J34_UoRm",
        "outputId": "e50ccf9b-4456-414f-f0c5-50bc2c6c0cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   gb learning rate  gb mean accuracy\n",
            "0               0.1         82.661616\n",
            "1               0.2         80.661616\n",
            "2               0.3         80.202020\n",
            "3               0.4         78.409091\n",
            "4               0.5         78.176768\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Gradient Boost Classification Model relies heavily on values for different hyperparameters. The learning rate of .10 has the highest mean accuracy and is the default for this model. I will not need to change this hyperparameter for the validation and test sets."
      ],
      "metadata": {
        "id": "OCCZxjoFU9Xh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep2NIZeex_yj"
      },
      "source": [
        "# Step 8: Evaluate Your Best Model\n",
        "\n",
        "Evaluate your best model using the test set. \n",
        "\n",
        "*   Which model fit the data best?\n",
        "*   What was the best accuracy you were able to achieve?  \n",
        "\n",
        "**Note**: Use comments in your code and text blocks to explain your decisions and results."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model with the highest accuracy is the GradientBoost Classifier. The average accuracy of this model is 82.6% for the training set. The single best accuracy score I was able to achieve was 88.9%. This was the second fold of the 10-fold cross validation for both the GradientBoost pipeline and the first KNN pipelines."
      ],
      "metadata": {
        "id": "a52IlOP6Xa9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gradient Boost - evaluate validation set to ensure there isn't any overfitting\n",
        "gb_pipe.fit(X_val, y_val)\n",
        "\n",
        "gb_val_scores = cross_val_score(gb_pipe, X_val, y_val, cv=10)\n",
        "\n",
        "print(gb_val_scores)\n",
        "\n",
        "print(gb_val_scores.mean())\n",
        "print(gb_val_scores.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nIYUYXfRc6c",
        "outputId": "704470e4-8ad6-43c8-c4d2-049c8a4d5cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.82608696 0.82608696 0.86956522 0.81818182 0.86363636 0.72727273\n",
            " 0.81818182 0.68181818 0.90909091 0.86363636]\n",
            "0.8203557312252965\n",
            "0.06478747989123315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The validation set has an average accuracy score of .820 and a standard deviation .064. The GradientBoost model can accurately predict a passenger's survival on the Titanic 82.0% of the time. While the accuracy percentage of the training set is higher (82.6%), there is not a huge discrepency and we can assume the GradientBoost model is not overfitting the data in the training set."
      ],
      "metadata": {
        "id": "aBEEkok3Yjza"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u20nsPshZb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e30cf9-32e0-4576-f883-633a97c5e514"
      },
      "source": [
        "# Step 8 - Test GradientBoost\n",
        "gb_pipe.fit(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('imp_mean', SimpleImputer()), ('scaler', StandardScaler()),\n",
              "                ('Gradient',\n",
              "                 GradientBoostingClassifier(learning_rate=0.5,\n",
              "                                            random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GradientBoost- FINAL TEST SCORES\n",
        "gb_test_scores = cross_val_score(gb_pipe, X_test, y_test, cv=10)\n",
        "\n",
        "print(gb_test_scores)\n",
        "\n",
        "print(gb_test_scores.mean())\n",
        "print(gb_test_scores.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8lk3uyKRQpW",
        "outputId": "a0730d06-0fcf-4b9d-d6c2-b12e65855d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.91304348 0.60869565 0.69565217 0.77272727 0.77272727 0.72727273\n",
            " 0.77272727 0.81818182 0.77272727 0.63636364]\n",
            "0.7490118577075099\n",
            "0.08344977205817158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The GradientBoost model accurately classifies a passenger's survival on the Titanic accurately 74.9% of the time in the test set with a relatively high standard deviation of .083."
      ],
      "metadata": {
        "id": "Ng6OD7B1cCOA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 9: Final Reporting\n",
        "\n",
        "Summarize your model building process:  \n",
        "* How did you identify the model target and features?  \n",
        "* What steps did you take to prepare the data for modeling?  \n",
        "* Which baseline model did you choose and why? How did you evaluate the model's performance?  \n",
        "* Which other model(s) did you choose and why? How did you evaluate the model's performace?  \n",
        "* What was the best model you developed? How well did the model perform on the test data?"
      ],
      "metadata": {
        "id": "JYcXAvwtyrnA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 9:\n",
        "**Indentifying target/prepping data:**\n",
        "\n",
        "I determined that the model target was 'Survived.' The machine learning models use the features (the remaining columns) to determine the probability of a passenger survining the sinking of the Titanic. Ultimately, I dropped 'PassengerId', 'Name', and 'Ticket' from my dataframe because they did not provide any useful information other than identification for the set. I also omitted 'Cabin' from my final dataframe because the only passengers who had cabin numbers were in first class. There were only 204 cabins assigned for the the 891 passengers aboard the Titanic (roughly 77% of the data in this column was null). Unlike the 'Cabin' column, I chose to impute the 'Age' feature using mean. I waited until after the train_test_split to impute the ages in order to avoid data leakage. I chose to one-hot encode both the 'Sex' and 'Embarked' columns. Both variables are nominal and do not have an inherent heirarchy.\n",
        "\n",
        "\n",
        "**Baseline model:**\n",
        "\n",
        "Since the models are trying to correctly determine whether a passenger would survive the sinking of the Titanic, I decided to use classification algorithms. I started with Logistic Regression Model because it is the most common and basic classification model we disussed in class. It is also the easiest to explain to other people. I ran the Logistic Regression with all of the remaining features first ('Pclass', 'Sex', 'Age', 'Fare', 'SibSp', 'Parch', 'Embarked'). The accuracy score was .798, meaning that it accurately classified if someone survived 79.8% of the time. After removing the features with family connections (Sibsp, Parch), the accuracy decreased to 78.9%. When ticket fare was removed (as it is closely related to passenger class), the accuracy to 79.1%, but it is still lower than the initial baseline model. Removing the cities of embarkment had an accuracy percentage of 79.3%. Like removing the fare feature, it is more accurate than removing family members but less accurate than including all of the features.\n",
        "\n",
        "**Other models:**\n",
        "\n",
        "The models I chose were the KNN Nearest Neighbors Model, the Naive Bayes Classification Model, and the Decision Tree Classifier Model. In each case, I needed to examine if passengers survived or not. Because the result is not numeric, I needed to use classification models. I was also working with supervised data where I had proper labels, which is compatible with the models I chose. I evaluated each model on its mean accuracy score and standard deviation, derived from 10-fold cross validation. Of the models I worked with, the KNN Nearest Neighbors model produced the second greatest mean accuracy percentage and lowest standard deviation (81.1% and .044 respectively). I chose the KNN Nearest Neighbors model because, like the logistic regression model, it is relatively simple to understand and explain. The Naive Bayes Classification Model had second highest mean accuracy percentage (77.3%) for the other models group. I chose to work with this particular model because I like that it treats each feature independently. Even though it is not as accurate as other models and has a tendency towards overfitting, I chose the Decision Tree Classifier Model because it is incredibly intuitive and easy to explain to other people. The two versions I ran were the poorest performing models, with the 'entropy' version being the worst. The entropy version of the model was only averaging 74.1% accuracy and had the highest standard deviation at .089. The final two models I used were AdaBoost and GradientBoost. These are considered the most effective classification models and thus an optimal choice for this exercise, but are more difficult to explain to others. The AdaBoost model had an average mean accuracy of 79.6% and a standard deviation of .049. Although it was one of the better performing models, it did not have the highest mean accuracy score. The model that ultimately had the highest mean accuracy score was the GradientBoost Classification Model. This model had a mean accuracy score of .826 and a standard deviation of .047. Not only did the model correctly classify a passenger's survival an average of 82.6% of the time (1.5% more then the next highest model), but the scores within the 10-fold cross validation were also consistent with one another.\n",
        "\n",
        "**Best model:**\n",
        "\n",
        "The best model I developed was the GradientBoost Classification Model. It had the highest mean accuracy percentage at 82.6% with the training set. When I ran the validation set, the accuracy decreased to 82.0%, but it was clear that the model was not overfit to the training set. When I ran the final test set for the GradientBoost Model, it had a mean accuracy of 74.9% and a standard deviation of .083. This means the the model correctly identified a passenger's survival, on average, 3 out of 4 times. The scores were not nearly as consistent throughout the 10-fold cross validation process as the training and validation sets. While correctly classifying a passenger's survival 75% of the time is sufficient for examining an event that happened 110 years ago, it would not be a high enough percentage if we were trying to determine something more critical (e.g. whether someone has cancer or not)."
      ],
      "metadata": {
        "id": "6x9-IRv6zZlO"
      }
    }
  ]
}